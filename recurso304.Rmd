---
title : <span style="color:#034a94"> **Métodos de estimación**</span>
author: "Métodos y Simulación estadística"
output:
  html_document:
    toc: no
    toc_depth: 2
    toc_float: yes
    code_folding: hide
    css: style.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, comment = NA)
```


La construcción de estimadores de parámetros tiene un soporte matemático que está basado en  el valor esperado y las funciones de probabilidad revisadas anteriormente. También supone que las muestras son tomadas aleatoriamente y que valores obtenidos son independiente unos de otros. 

A continuación se presentan el método de Momentos y el **método de Máxima Verosimilitud**:


### <span style="color:#034a94">**Método de momentos**</span>

<br/>

El **método de momentos** fue propuesto por Karl Pearson al rededor de 1895, pensado en sus inicios en contexto descriptivo, analizando las distribuciones de probabilidad y aproximándolas al sistema de curvas que llevan su nombre. Posteriormente este concepto fue modificado por R.A. Fisher en 1920. El método consiste en estimar un parámetro de una distribución igualando sus momentos teóricos o poblacionales, si existen, con los correspondientes momentos muestrales.

Para mostrar este método es necesario definir el concepto de momento.

<br/>

<div class="content-box-blue">
### <span style="color:#034a94">**Momento Poblacional**</span> 


|  caso variable discreta                         |caso variable continua  |
|:------------------------------------------------|:------------------------------------------------|
|$\mu^{k}=E\big[X^{k}\big] = \displaystyle\sum_{R_X} x^{k}p(x)$ |$\mu^{k}=E\big[X^{k}\big]=\int_{-\infty}^{\infty}x^{k}f(x)\:dx$|

</div>
<br/>

### <span style="color:#034a94">**Momentos muestrales**</span>    

En ambos casos

$$m^{k}=\frac{1}{n}\sum_{i=1}^{n} x_{i}^{k} $$  

El método de momentos supone que los momentos tanto poblacionales como muestrales son conocidos, y por lo tanto también la función de probabilidad. 

A continuación se relacionan algunos de estos momentos poblacionales:

<br

<center>

**Tabla 2.7**  Valor esperado y varianza de los principales modelos de probabilidad

| Distribución | $E[X]$               | $V[X]=E[X^{2}]-E[X]^{2}$        |
|:-------------|:---------------------|:--------------------------------|
| bernoulli    | $p$                  | $pq$                            |
| geométrica   | $\displaystyle\frac{1}{p}$ | $\displaystyle\frac{q}{p^{2}}$  |
| binomial     | $np$                 | $npq$                           |
| Poisson      | $\lambda$            | $\lambda$                       | 
| gamma        | $\alpha\beta$        | $\alpha\beta^{2}$               |
| exponencial  | $\beta$              | $\beta^{2}$                     | 
| uniforme     | $\displaystyle\frac{a+b}{2}$| $\displaystyle\frac{(b-a)^{2}}{12}$ |
| normal       | $\mu$                |$\sigma^{2}$                     |

</center>

<br/>

<div class="content-box-gray">
### <span style="color:#686868">**Nota**</span> 

Existe una relación entre las distribuciones `Poisson` y `exponencial`. Su valores esperados son inversos y e podrían denotar en función de $\lambda$, haciendo $\beta=\dfrac{1}{\lambda}$  

</div>

<br/><br/>

### <span style="color:#FF7F00"> **Ejemplo**</span>

<br/>

Encuentre los estimadores de los parámetros de la distribución normal a través del método de momentos.
Previamente sabemos que los parámetros de una variable con distribución normal son $E[X]=\mu$ y $V[X]=\sigma^{2}$ y que $V[X]=E[X^{2}]-E[X]^{2}$. Dada esta información el estimador de momentos se construye de la siguiente manera: 

$$M^{1}=m^{1}$$

$$M^{2}=m^{2}$$

Aplicando el método:

<br/>

|                                                    |
|:---------------------------------------------------|
|$$M^{1}= m^{1}$$ |
|$$\mu  =  \displaystyle\frac{1}{n}\sum_{i=1}^{n}x_{i}$$|
|$$\widehat{\mu} = \displaystyle\frac{1}{n}\sum_{i=1}^{n} x_{i}=\bar{x}$$|


<br/>

Para estimar $\sigma^{2}$, se realiza el siguiente procedimiento, usando $\mu^{1}=m^{1}$  y $\mu^{2}=m^{2}$.

$$V[X]=E[X^{2}]-E[X]^{2} = \mu^{2}-(\mu^{1})^{2}$$

entonces igualamos estos dos momentos poblacionales con sus respectivos momentos muestrales quedando la igualdad

$$\begin{eqnarray*}
	V[X]&=& \mu^{2}-(\mu^{1})^{2}\\
	&=&m^{2}-(m^{1})^{2}\\
	&=&\displaystyle\frac{1}{n}\sum_{i=1}^{n}x_{i}^{2}-\bar{x}^{2}
\end{eqnarray*}$$

podemos representar la varianza por $\sigma^{2}$ y obtenemos

$$\widehat{\sigma^{2}}=\displaystyle\frac{1}{n}\sum_{i=1}^{n}x_{i}^{2}-\bar{x}^{2}$$

y obtenemos el estimador de la varianza:

<br/>

|                       |                                                                                                   |
|----------------------:|:--------------------------------------------------------------------------------------------------|
|$\widehat{\sigma^{2}}$ | $= \displaystyle\frac{1}{n}\sum_{i=1}^{n}x_{i}^{2}-\bar{x}^{2}$                                   |
|$\widehat{\sigma^{2}}$ | $= \displaystyle\frac{1}{n}\sum_{i=1}^{n}x_{i}^{2}-\bar{x}^{2}-\bar{x}^{2}+\bar{x}^{2}$           |
|                       | $= \displaystyle\frac{1}{n}\sum_{i=1}^{n}x_{i}^{2}-2\bar{x}^{2}+\bar{x}^{2}$                      |
|                       | $= \displaystyle\frac{1}{n}\sum_{i=1}^{n}x_{i}^{2}-\displaystyle\frac{2\bar{x}\sum x_{i}}{n}+\displaystyle\frac{n \bar{x}^{2}}{n}$ |
|                       | $= \displaystyle\frac{1}{n}\Big(\sum_{i=1}^{n} x_{i}^{2}-2\bar{x}\sum_{i=1}^{n} x_{i}+\bar{x}^{2}\Big)$ |
|                       | $= \displaystyle\frac{1}{n}\sum_{i=1}^{n}\Big(x_i-\bar{x}\Big)^{2}$        |

<br/><br/>

En resumen los estimadores de momentos para los parámetros de la distribución normal son:


$$\widehat{\mu} = \displaystyle\frac{1}{n}\sum_{i=1}^{n} x_{i}=\bar{x}$$

$$\widehat{\sigma^{2}} = \displaystyle\frac{1}{n}\sum_{i=1}^{n}\Big(x-\bar{x}\Big)^{2}$$ 


A partir de ellos y mediante la obtención de una muestra aleatoria por ejemplo :630, 650, 710, 750, 790, 820, 860 y 910 se pueden estimar los parámetros por método de momentos con los siguientes resultados:

$$\widehat{\mu}=765$$  

$$\widehat{\sigma^{2}}=8550$$

<br/><br/><br/><br/>
